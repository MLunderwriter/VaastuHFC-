{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_7680\\2546687590.py:5: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df =  pd.read_csv(path+filename, sep = \"|\",error_bad_lines=False)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_7680\\2546687590.py:5: DtypeWarning: Columns (4,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df =  pd.read_csv(path+filename, sep = \"|\",error_bad_lines=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1554704, 42),\n",
       "                   CREDT_RPT_ID  LOS_APP_ID  CANDIDATE__ID  CUSTOMER_ID_MBR_ID  \\\n",
       " 0  VAST221119CR130117923734081  N004500061      208985439                 NaN   \n",
       " 1  VAST221119CR130117923734081  N004500061      140942914                 NaN   \n",
       " 2  VAST221119CR130117923734081  N004500061      159060193                 NaN   \n",
       " 3  VAST221119CR130117923734081  N004500061      812520964                 NaN   \n",
       " 4  VAST221119CR130117923734081  N004500061      559060193                 NaN   \n",
       " \n",
       "   BRANCH KENDRA  SELF_INDICATOR MATCH_TYPE ACC_NUM CREDIT_GRANTOR  ...  \\\n",
       " 0    NaN    NaN           False    PRIMARY    XXXX           XXXX  ...   \n",
       " 1    NaN    NaN           False    PRIMARY    XXXX           XXXX  ...   \n",
       " 2    NaN    NaN           False    PRIMARY    XXXX           XXXX  ...   \n",
       " 3    NaN    NaN           False    PRIMARY    XXXX           XXXX  ...   \n",
       " 4    NaN    NaN           False    PRIMARY    XXXX           XXXX  ...   \n",
       " \n",
       "                                      HIGH_CRD__HIST_  \\\n",
       " 0  34500000,34500000,34500000,34500000,34500000,3...   \n",
       " 1         375000,375000,375000,375000,375000,375000,   \n",
       " 2  950000,950000,950000,950000,950000,950000,9500...   \n",
       " 3  1050000,1050000,1050000,1050000,1050000,105000...   \n",
       " 4  700000,700000,700000,700000,700000,700000,7000...   \n",
       " \n",
       "                                       CUR_BAL__HIST_  \\\n",
       " 0  35119563,35565363,34335577,34807159,34479803,3...   \n",
       " 1               0,32221,358221,396181,415161,434141,   \n",
       " 2  0,137284,908284,942784,977264,1011764,1046264,...   \n",
       " 3  0,131180,167330,203456,239700,273988,384052,42...   \n",
       " 4  0,100180,668630,694130,719610,745110,770610,79...   \n",
       " \n",
       "                                           DAS__HIST_  \\\n",
       " 0            S05S05S05S05S05S05S05S05S05S04S04S04S04   \n",
       " 1                                 S07S04S04S04S04S04   \n",
       " 2                  S07S04S04S04S04S04S04S04S04S04S04   \n",
       " 3  S07S04S04S04S04S04S05S05S05S05S05S05S05S04S04S...   \n",
       " 4                  S07S04S04S04S04S04S04S04S04S04S04   \n",
       " \n",
       "                                   AMT_OVERDUE__HIST_  \\\n",
       " 0  222788,595674,640621,1045656,650951,756519,362...   \n",
       " 1                                             ,,,,,,   \n",
       " 2                                        ,,,,,,,,,,,   \n",
       " 3  ,,,,,,60412,63105,61195,63650,62254,61932,2597...   \n",
       " 4                                        ,,,,,,,,,,,   \n",
       " \n",
       "                                      AMT_PAID__HIST_ INCOME_  \\\n",
       " 0  783727.50,400000,800000,0,500000,0,800000,0,0,...     0.0   \n",
       " 1         375000,375000,375000,375000,375000,375000,     0.0   \n",
       " 2  950000,950000,950000,950000,950000,950000,9500...     0.0   \n",
       " 3  1050000,1050000,1050000,1050000,1050000,105000...     0.0   \n",
       " 4  700000,700000,700000,700000,700000,700000,7000...     0.0   \n",
       " \n",
       "   _INCOME_INDICATOR_ TENURE_ _OCCUPATION Unnamed_41  \n",
       " 0                NaN   170.0         NaN        NaN  \n",
       " 1                NaN    23.0         NaN        NaN  \n",
       " 2                NaN    35.0         NaN        NaN  \n",
       " 3                NaN    35.0         NaN        NaN  \n",
       " 4                NaN    35.0         NaN        NaN  \n",
       " \n",
       " [5 rows x 42 columns])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"D:/Vaastu/Data/VASTU_SCORE_CARD_111122_2_1_Output/\"\n",
    "path = \"D:/Vaastu/Data/VASTU_SCORE_CARD_111122_2_1_Retro_Output/VASTU_SCORE_CARD_111122_2_1_Retro_Output/\"\n",
    "filename = \"Account.csv\"\n",
    "\n",
    "df =  pd.read_csv(path+filename, sep = \"|\",error_bad_lines=False)\n",
    "\n",
    "colnames = df.columns\n",
    "newcolnames = []\n",
    "for col in colnames:\n",
    "    newcol = col.replace(\" \", \"_\")\n",
    "    newcol = newcol.replace(\"-\", \"_\")\n",
    "    newcol = newcol.replace(\"/\", \"_\")\n",
    "    newcol = newcol.replace(\":\", \"_\")\n",
    "    newcol = newcol.replace(\"__\", \"_\")\n",
    "    newcolnames.append(newcol)\n",
    "    \n",
    "    \n",
    "df.columns = newcolnames\n",
    "from datetime import date\n",
    "df['DISBURSED_DT'] = pd.to_datetime(df['DISBURSED_DT'],format=\"%d-%m-%Y\",errors='coerce')\n",
    "df['DATE_REPORTED'] = pd.to_datetime(df['DATE_REPORTED'],format=\"%d-%m-%Y\",errors='coerce')\n",
    "\n",
    "df.shape, df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"df_retro_entire.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((525133, 48), 75753, (85950, 48), 36886)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import base with CV tradelines having atleast 18MOB of data\n",
    "df_cv= pd.read_pickle(\"df_cv_filtered.pkl\")\n",
    "df_cv['DISBURSED_DT_YRMTH']=df_cv['DISBURSED_DT'].dt.strftime('%Y-%m')\n",
    "df_cv['DATE_REPORTED_YRMTH']=df_cv['DATE_REPORTED'].dt.strftime('%Y-%m')\n",
    "\n",
    "df_cv['DISBURSED_DT_YR']=df_cv['DISBURSED_DT'].dt.strftime('%Y')\n",
    "df_cv['DATE_REPORTED_YR']=df_cv['DATE_REPORTED'].dt.strftime('%Y')\n",
    "\n",
    "#Include only NBF Loans, Individual,  Disbursed Years : 2015 - 2019\n",
    "\n",
    "\n",
    "cond1 = (df_cv.OWNERSHIP_IND == 'Individual')\n",
    "cond2 = (df_cv.CONTRIBUTOR_TYPE == 'NBF')\n",
    "cond3 = (df_cv.DISBURSED_DT_YR.isin(['2015','2016','2017','2018','2019']))\n",
    "\n",
    "df_cv_filtered = df_cv[cond1 & cond2 & cond3 ]\n",
    "\n",
    "df_cv.shape, df_cv['LOS_APP_ID'].nunique() , df_cv_filtered.shape, df_cv_filtered['LOS_APP_ID'].nunique()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8984\\2491307517.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_filtered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_cv_filtered\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLOS_APP_ID\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'LOS_APP_ID'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'LOS_APP_ID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'inner'\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf_filtered\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"df_retro_filtered.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'LOS_APP_ID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mdf_filtered\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_filtered\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'LOS_APP_ID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df_filtered = df.merge(pd.DataFrame(df_cv_filtered.LOS_APP_ID.unique() , columns = ['LOS_APP_ID'] ) , on = 'LOS_APP_ID', how='inner' )\n",
    "df_filtered.to_pickle(\"df_retro_filtered.pkl\")\n",
    "\n",
    "df.shape, df['LOS_APP_ID'].nunique() , df_filtered.shape, df_filtered['LOS_APP_ID'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_cv_filtered_v2 = df_cv_filtered.merge(pd.DataFrame(df_filtered.LOS_APP_ID.unique() , columns = ['LOS_APP_ID'] ) , on = 'LOS_APP_ID', how='inner' )\n",
    "\n",
    "df_cv_filtered_v2.to_pickle(\"df_goodbad_filtered.pkl\")\n",
    "df_cv_filtered.shape, df_cv_filtered['CANDIDATE__ID'].nunique() , df_cv_filtered_v2.shape, df_cv_filtered_v2['LOS_APP_ID'].nunique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((83364, 48), (869346, 42))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Reading processed datasets\n",
    "df_cv_goodbad= pd.read_pickle(\"df_goodbad_filtered.pkl\")\n",
    "df_cv_retro = pd.read_pickle(\"df_retro_filtered.pkl\")\n",
    "\n",
    "df_cv_goodbad.shape, df_cv_retro.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34718, 3), (33679, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "firstdate_curr_scrub = df_cv_goodbad.groupby('LOS_APP_ID').agg({'DISBURSED_DT' : min}).reset_index()\n",
    "firstdate_curr_scrub.rename(columns = {'DISBURSED_DT':'DISBURSED_DT_curr_scrub'}, inplace = True)\n",
    "\n",
    "first_date_retro_scrub = df_cv_retro.groupby('LOS_APP_ID').agg({'DISBURSED_DT' : min}).reset_index()\n",
    "first_date_retro_scrub.rename(columns = {'DISBURSED_DT':'DISBURSED_DT_retro_scrub'}, inplace = True)\n",
    "\n",
    "\n",
    "df_cv_retro_map = first_date_retro_scrub.merge(firstdate_curr_scrub, how=\"left\" , on =\"LOS_APP_ID\")\n",
    "from datetime import date\n",
    "#df_cv_retro_map['DISBURSED_DT_curr_scrub'] = pd.to_datetime(df_cv_retro_map['DISBURSED_DT'],format=\"%d-%m-%Y\",errors='coerce')\n",
    "#df_cv_retro_map['DATE_REPORTED'] = pd.to_datetime(df_cv_retro_map['DATE_REPORTED'],format=\"%d-%m-%Y\",errors='coerce')\n",
    "#df_cv_retro_map['DISBURSED_DT_goodbad'] = pd.to_datetime(df_cv_retro_map['DISBURSED_DT_goodbad'],format=\"%d-%m-%Y\",errors='coerce')\n",
    "\n",
    "\n",
    "df_cv_retro_map.shape, df_cv_retro_map[df_cv_retro_map['DISBURSED_DT_retro_scrub'] < df_cv_retro_map['DISBURSED_DT_curr_scrub']].shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "10\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8984\\1770647874.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "(83364, 83)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REPORTED_DATE__HIST_</th>\n",
       "      <th>Reported_Dt1</th>\n",
       "      <th>Reported_Dt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20180831,20180731,20180630,20180531,20180430,2...</td>\n",
       "      <td>2018-08-31</td>\n",
       "      <td>2018-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20180831,20180731,20180630,20180531,20180430,2...</td>\n",
       "      <td>2018-08-31</td>\n",
       "      <td>2018-07-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                REPORTED_DATE__HIST_ Reported_Dt1 Reported_Dt2\n",
       "0  20180831,20180731,20180630,20180531,20180430,2...   2018-08-31   2018-07-31\n",
       "1  20180831,20180731,20180630,20180531,20180430,2...   2018-08-31   2018-07-31"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['Loan_id',\"DISBURSED_DT\",\"DATE_REPORTED\" ,'LOS_APP_ID' , \"ACCOUNT_STATUS\",\n",
    "        \"REPORTED_DATE__HIST_\",\"DPD__HIST\",\n",
    "       \"AMT_OVERDUE__HIST_\",\"CUR_BAL__HIST_\" ]\n",
    "df_cv_goodbad['Loan_id'] = df_cv_goodbad.reset_index().index\n",
    "\n",
    "temp = df_cv_goodbad[cols]\n",
    "#temp['DPD__HIST'] = temp['DPD__HIST'].astype(str) \n",
    "for n in range(37):\n",
    "    print(n+1)\n",
    "    st= n*3\n",
    "    lst =(n+1)*3\n",
    "    #print(st,lst)\n",
    "    temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
    "    st= n*8 + n\n",
    "    lst =(n+1)*8 + n\n",
    "    #print(st,lst)\n",
    "    temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
    "    temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n",
    "\n",
    "\n",
    "\n",
    "print(temp.shape)\n",
    "\n",
    "temp[['REPORTED_DATE__HIST_', 'Reported_Dt1','Reported_Dt2']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83364, 83)\n",
      "(83364, 120)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUR_BAL__HIST_</th>\n",
       "      <th>CUR_BAL1</th>\n",
       "      <th>CUR_BAL2</th>\n",
       "      <th>CUR_BAL3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0,0,14570,29440,44310,59180,74050,88920,103790...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0,116777,154755,192265,229311,265901,302038,33...</td>\n",
       "      <td>0</td>\n",
       "      <td>116777</td>\n",
       "      <td>154755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0,28742,42834,56744,70474,,97401,110603,123634...</td>\n",
       "      <td>0</td>\n",
       "      <td>28742</td>\n",
       "      <td>42834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0,13243,26294,39152,51820,64300,76596,88710,10...</td>\n",
       "      <td>0</td>\n",
       "      <td>13243</td>\n",
       "      <td>26294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      CUR_BAL__HIST_ CUR_BAL1 CUR_BAL2  \\\n",
       "0  0,0,14570,29440,44310,59180,74050,88920,103790...        0        0   \n",
       "1  0,116777,154755,192265,229311,265901,302038,33...        0   116777   \n",
       "2  0,28742,42834,56744,70474,,97401,110603,123634...        0    28742   \n",
       "3  0,13243,26294,39152,51820,64300,76596,88710,10...        0    13243   \n",
       "\n",
       "  CUR_BAL3  \n",
       "0    14570  \n",
       "1   154755  \n",
       "2    42834  \n",
       "3    26294  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "met = 'AMT_OVERDUE'\n",
    "col =\"AMT_OVERDUE__HIST_\"\n",
    "\n",
    "names_arr = []\n",
    "for n in range(1,38):\n",
    "    names_arr.append(met + str(n))\n",
    "    \n",
    "print(temp.shape)\n",
    "temp[names_arr] = temp[col].str.split(',', expand=True)\n",
    "\n",
    "met = 'CUR_BAL'\n",
    "col =\"CUR_BAL__HIST_\"\n",
    "\n",
    "names_arr = []\n",
    "for n in range(1,38):\n",
    "    names_arr.append(met + str(n))\n",
    "    \n",
    "print(temp.shape)\n",
    "temp[names_arr] = temp[col].str.split(',', expand=True)\n",
    "\n",
    "\n",
    "\n",
    "temp[['CUR_BAL__HIST_','CUR_BAL1','CUR_BAL2','CUR_BAL3']].head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_id</th>\n",
       "      <th>DISBURSED_DT</th>\n",
       "      <th>DATE_REPORTED</th>\n",
       "      <th>LOS_APP_ID</th>\n",
       "      <th>ACCOUNT_STATUS</th>\n",
       "      <th>Month</th>\n",
       "      <th>CUR_BAL__HIST_</th>\n",
       "      <th>DPD__HIST</th>\n",
       "      <th>AMT_OVERDUE__HIST_</th>\n",
       "      <th>REPORTED_DATE__HIST_</th>\n",
       "      <th>CUR_BAL</th>\n",
       "      <th>Reported_Dt</th>\n",
       "      <th>DPD</th>\n",
       "      <th>AMT_OVERDUE</th>\n",
       "      <th>MOB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-27</td>\n",
       "      <td>2018-08-31</td>\n",
       "      <td>L022500180</td>\n",
       "      <td>Closed</td>\n",
       "      <td>1</td>\n",
       "      <td>0,0,14570,29440,44310,59180,74050,88920,103790...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>,,,,,,,,,,,,,,,,,,,,,,,,,,</td>\n",
       "      <td>20180831,20180731,20180630,20180531,20180430,2...</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-08-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.133986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-27</td>\n",
       "      <td>2018-08-31</td>\n",
       "      <td>L022500180</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2</td>\n",
       "      <td>0,0,14570,29440,44310,59180,74050,88920,103790...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>,,,,,,,,,,,,,,,,,,,,,,,,,,</td>\n",
       "      <td>20180831,20180731,20180630,20180531,20180430,2...</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.115485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-27</td>\n",
       "      <td>2018-08-31</td>\n",
       "      <td>L022500180</td>\n",
       "      <td>Closed</td>\n",
       "      <td>3</td>\n",
       "      <td>0,0,14570,29440,44310,59180,74050,88920,103790...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>,,,,,,,,,,,,,,,,,,,,,,,,,,</td>\n",
       "      <td>20180831,20180731,20180630,20180531,20180430,2...</td>\n",
       "      <td>14570</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.096984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-27</td>\n",
       "      <td>2018-08-31</td>\n",
       "      <td>L022500180</td>\n",
       "      <td>Closed</td>\n",
       "      <td>4</td>\n",
       "      <td>0,0,14570,29440,44310,59180,74050,88920,103790...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>,,,,,,,,,,,,,,,,,,,,,,,,,,</td>\n",
       "      <td>20180831,20180731,20180630,20180531,20180430,2...</td>\n",
       "      <td>29440</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.111337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-27</td>\n",
       "      <td>2018-08-31</td>\n",
       "      <td>L022500180</td>\n",
       "      <td>Closed</td>\n",
       "      <td>5</td>\n",
       "      <td>0,0,14570,29440,44310,59180,74050,88920,103790...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>,,,,,,,,,,,,,,,,,,,,,,,,,,</td>\n",
       "      <td>20180831,20180731,20180630,20180531,20180430,2...</td>\n",
       "      <td>44310</td>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.092836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Loan_id DISBURSED_DT DATE_REPORTED  LOS_APP_ID ACCOUNT_STATUS  Month  \\\n",
       "0        0   2016-07-27    2018-08-31  L022500180         Closed      1   \n",
       "1        0   2016-07-27    2018-08-31  L022500180         Closed      2   \n",
       "2        0   2016-07-27    2018-08-31  L022500180         Closed      3   \n",
       "3        0   2016-07-27    2018-08-31  L022500180         Closed      4   \n",
       "4        0   2016-07-27    2018-08-31  L022500180         Closed      5   \n",
       "\n",
       "                                      CUR_BAL__HIST_  \\\n",
       "0  0,0,14570,29440,44310,59180,74050,88920,103790...   \n",
       "1  0,0,14570,29440,44310,59180,74050,88920,103790...   \n",
       "2  0,0,14570,29440,44310,59180,74050,88920,103790...   \n",
       "3  0,0,14570,29440,44310,59180,74050,88920,103790...   \n",
       "4  0,0,14570,29440,44310,59180,74050,88920,103790...   \n",
       "\n",
       "                                           DPD__HIST  \\\n",
       "0  0000000000000000000000000000000000000000000000...   \n",
       "1  0000000000000000000000000000000000000000000000...   \n",
       "2  0000000000000000000000000000000000000000000000...   \n",
       "3  0000000000000000000000000000000000000000000000...   \n",
       "4  0000000000000000000000000000000000000000000000...   \n",
       "\n",
       "           AMT_OVERDUE__HIST_  \\\n",
       "0  ,,,,,,,,,,,,,,,,,,,,,,,,,,   \n",
       "1  ,,,,,,,,,,,,,,,,,,,,,,,,,,   \n",
       "2  ,,,,,,,,,,,,,,,,,,,,,,,,,,   \n",
       "3  ,,,,,,,,,,,,,,,,,,,,,,,,,,   \n",
       "4  ,,,,,,,,,,,,,,,,,,,,,,,,,,   \n",
       "\n",
       "                                REPORTED_DATE__HIST_ CUR_BAL Reported_Dt  DPD  \\\n",
       "0  20180831,20180731,20180630,20180531,20180430,2...       0  2018-08-31  0.0   \n",
       "1  20180831,20180731,20180630,20180531,20180430,2...       0  2018-07-31  0.0   \n",
       "2  20180831,20180731,20180630,20180531,20180430,2...   14570  2018-06-30  0.0   \n",
       "3  20180831,20180731,20180630,20180531,20180430,2...   29440  2018-05-31  0.0   \n",
       "4  20180831,20180731,20180630,20180531,20180430,2...   44310  2018-04-30  0.0   \n",
       "\n",
       "   AMT_OVERDUE        MOB  \n",
       "0          NaN  25.133986  \n",
       "1          NaN  24.115485  \n",
       "2          NaN  23.096984  \n",
       "3          NaN  22.111337  \n",
       "4          NaN  21.092836  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_long=pd.wide_to_long(temp, \n",
    "                stubnames=['CUR_BAL','Reported_Dt','DPD','AMT_OVERDUE'], \n",
    "                i=['Loan_id',\"DISBURSED_DT\",\"DATE_REPORTED\" ,'LOS_APP_ID' , \"ACCOUNT_STATUS\"], \n",
    "                j='Month').reset_index()\n",
    "\n",
    "df_long['MOB'] = ((df_long.Reported_Dt - pd.to_datetime(df_long.DISBURSED_DT) )/np.timedelta64(1, 'M'))\n",
    "\n",
    "df_long['DPD']=pd.to_numeric(df_long['DPD'], errors = 'coerce')\n",
    "df_long['AMT_OVERDUE']=pd.to_numeric(df_long['AMT_OVERDUE'], errors = 'coerce')\n",
    "df_long['AMT_OVERDUE']=pd.to_numeric(df_long['AMT_OVERDUE'], errors = 'coerce')\n",
    "df_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((81564, 5), 0.4365651512922368, 0.2146044823696729, 0.1159089794517189)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#18 months\n",
    "loan_agg = df_long[df_long['MOB'] <= 18].groupby('Loan_id').agg({'DPD' : max}).reset_index()\n",
    "loan_agg['DPD_1_plus_18'] = np.where(loan_agg['DPD'] > 0 ,1,0)\n",
    "loan_agg['DPD_30_plus_18'] = np.where(loan_agg['DPD'] > 30 ,1,0)\n",
    "loan_agg['DPD_60_plus_18'] = np.where(loan_agg['DPD'] > 60 ,1,0)\n",
    "\n",
    "loan_agg.shape,loan_agg.DPD_1_plus_18.mean(),loan_agg.DPD_30_plus_18.mean(),loan_agg.DPD_60_plus_18.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34305, 5), 0.5323422241655735, 0.2979449059903804, 0.17023757469756595)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cus_agg = df_long[df_long['MOB'] <= 18].groupby('LOS_APP_ID').agg({'DPD' : max}).reset_index()\n",
    "cus_agg['DPD_1_plus_18'] = np.where(cus_agg['DPD'] > 0 ,1,0)\n",
    "cus_agg['DPD_30_plus_18'] = np.where(cus_agg['DPD'] > 30 ,1,0)\n",
    "cus_agg['DPD_60_plus_18'] = np.where(cus_agg['DPD'] > 60 ,1,0)\n",
    "cus_agg.to_pickle('driverset_18M.pkl')\n",
    "cus_agg.shape,cus_agg.DPD_1_plus_18.mean(),cus_agg.DPD_30_plus_18.mean(),cus_agg.DPD_60_plus_18.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80930, 5), 0.3150006178178673, 0.12167305078462869, 0.053305325590016064)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#12 months\n",
    "loan_agg = df_long[df_long['MOB'] <= 12].groupby('Loan_id').agg({'DPD' : max}).reset_index()\n",
    "loan_agg['DPD_1_plus_12'] = np.where(loan_agg['DPD'] > 0 ,1,0)\n",
    "loan_agg['DPD_30_plus_12'] = np.where(loan_agg['DPD'] > 30 ,1,0)\n",
    "loan_agg['DPD_60_plus_12'] = np.where(loan_agg['DPD'] > 60 ,1,0)\n",
    "\n",
    "loan_agg.shape,loan_agg.DPD_1_plus_12.mean(),loan_agg.DPD_30_plus_12.mean(),loan_agg.DPD_60_plus_12.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34140, 5), 0.4131517281780902, 0.18588166373755127, 0.08728763913298183)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cus_agg2 = df_long[df_long['MOB'] <= 12].groupby('LOS_APP_ID').agg({'DPD' : max}).reset_index()\n",
    "cus_agg2['DPD_1_plus_12'] = np.where(cus_agg2['DPD'] > 0 ,1,0)\n",
    "cus_agg2['DPD_30_plus_12'] = np.where(cus_agg2['DPD'] > 30 ,1,0)\n",
    "cus_agg2['DPD_60_plus_12'] = np.where(cus_agg2['DPD'] > 60 ,1,0)\n",
    "\n",
    "cus_agg2.shape,cus_agg2.DPD_1_plus_12.mean(),cus_agg2.DPD_30_plus_12.mean(),cus_agg.DPD_60_plus_12.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cus_agg_vf= cus_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((869346, 43), (734211, 43))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_cv_retro = pd.read_pickle(\"df_retro_filtered.pkl\")\n",
    "\n",
    "firstdate_curr_scrub = df_cv_goodbad.groupby('LOS_APP_ID').agg({'DISBURSED_DT' : min}).reset_index()\n",
    "firstdate_curr_scrub.rename(columns = {'DISBURSED_DT':'DISBURSED_DT_curr_scrub'}, inplace = True)\n",
    "\n",
    "df_cv_retro= df_cv_retro.merge(firstdate_curr_scrub, how=\"inner\" , on =\"LOS_APP_ID\")\n",
    "\n",
    "\n",
    "from datetime import date\n",
    "df_cv_retro['DISBURSED_DT'] = pd.to_datetime(df_cv_retro['DISBURSED_DT'],format=\"%d-%m-%Y\",errors='coerce')\n",
    "df_cv_retro['DATE_REPORTED'] = pd.to_datetime(df_cv_retro['DATE_REPORTED'],format=\"%d-%m-%Y\",errors='coerce')\n",
    "df_cv_retro['DISBURSED_DT_curr_scrub'] = pd.to_datetime(df_cv_retro['DISBURSED_DT_curr_scrub'],format=\"%d-%m-%Y\",errors='coerce')\n",
    "df_cv_retro_useful = df_cv_retro[df_cv_retro['DISBURSED_DT'] < df_cv_retro['DISBURSED_DT_curr_scrub'] ]\n",
    "\n",
    "df_cv_retro.shape,df_cv_retro_useful.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cv_retro_useful['Loan_id'] = df_cv_retro_useful.reset_index().index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "(734211, 83)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(734211, 120)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n",
      "C:\\Users\\romil\\AppData\\Local\\Temp\\ipykernel_8840\\702606262.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp[names_arr] = temp[col].str.split(',', expand=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      CUR_BAL__HIST_ CUR_BAL1 CUR_BAL2  \\\n",
      "1               0,32221,358221,396181,415161,434141,        0    32221   \n",
      "2  0,137284,908284,942784,977264,1011764,1046264,...        0   137284   \n",
      "4  0,100180,668630,694130,719610,745110,770610,79...        0   100180   \n",
      "5                       0,0,23540,47120,70720,94320,        0        0   \n",
      "\n",
      "  CUR_BAL3  \n",
      "1   358221  \n",
      "2   908284  \n",
      "4   668630  \n",
      "5    23540  \n",
      "                                REPORTED_DATE__HIST_ Reported_Dt1 Reported_Dt2\n",
      "1  20141231,20141130,20141031,20140930,20140831,2...   2014-12-31   2014-11-30\n",
      "2  20150228,20150131,20141231,20141130,20141031,2...   2015-02-28   2015-01-31\n"
     ]
    }
   ],
   "source": [
    "cols = ['Loan_id',\"DISBURSED_DT\",\"DATE_REPORTED\" ,'LOS_APP_ID' , \"ACCOUNT_STATUS\", \"REPORTED_DATE__HIST_\",\"DPD__HIST\",\n",
    "       \"AMT_OVERDUE__HIST_\",\"CUR_BAL__HIST_\"]\n",
    "df_cv_retro_useful['Loan_id'] = df_cv_retro_useful.reset_index().index\n",
    "\n",
    "temp = df_cv_retro_useful[cols]\n",
    "#temp['DPD__HIST'] = temp['DPD__HIST'].astype(str) \n",
    "for n in range(37):\n",
    "    print(n+1)\n",
    "    st= n*3\n",
    "    lst =(n+1)*3\n",
    "    #print(st,lst)\n",
    "    temp['DPD' + str(n+1)]= temp.DPD__HIST.str.slice(st,lst)\n",
    "    st= n*8 + n\n",
    "    lst =(n+1)*8 + n\n",
    "    #print(st,lst)\n",
    "    temp['Reported_Dt' + str(n+1)]= temp['REPORTED_DATE__HIST_'].str.slice(st,lst)\n",
    "    temp['Reported_Dt' + str(n+1)] = pd.to_datetime(temp['Reported_Dt' + str(n+1)],format=\"%Y%m%d\",errors='coerce')\n",
    "\n",
    "\n",
    "met = 'AMT_OVERDUE'\n",
    "col =\"AMT_OVERDUE__HIST_\"\n",
    "\n",
    "names_arr = []\n",
    "for n in range(1,38):\n",
    "    names_arr.append(met + str(n))\n",
    "    \n",
    "print(temp.shape)\n",
    "temp[names_arr] = temp[col].str.split(',', expand=True)\n",
    "\n",
    "met = 'CUR_BAL'\n",
    "col =\"CUR_BAL__HIST_\"\n",
    "\n",
    "names_arr = []\n",
    "for n in range(1,38):\n",
    "    names_arr.append(met + str(n))\n",
    "    \n",
    "print(temp.shape)\n",
    "temp[names_arr] = temp[col].str.split(',', expand=True)\n",
    "\n",
    "print(temp[['CUR_BAL__HIST_','CUR_BAL1','CUR_BAL2','CUR_BAL3']].head(4))\n",
    "\n",
    "print(temp[['REPORTED_DATE__HIST_', 'Reported_Dt1','Reported_Dt2']].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((734211, 157), 33679, 734211)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.shape, temp.LOS_APP_ID.nunique(), temp.Loan_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CREDT_RPT_ID', 'LOS_APP_ID', 'CANDIDATE__ID', 'CUSTOMER_ID_MBR_ID',\n",
       "       'BRANCH', 'KENDRA', 'SELF_INDICATOR', 'MATCH_TYPE', 'ACC_NUM',\n",
       "       'CREDIT_GRANTOR', 'ACCT_TYPE', 'CONTRIBUTOR_TYPE', 'DATE_REPORTED',\n",
       "       'OWNERSHIP_IND', 'ACCOUNT_STATUS', 'DISBURSED_DT', 'CLOSE_DT',\n",
       "       'LAST_PAYMENT_DATE', 'CREDIT_LIMIT_SANC_AMT',\n",
       "       '_DISBURSED_AMT_HIGH_CREDIT', '_INSTALLMENT_AMT', '_CURRENT_BAL',\n",
       "       'INSTALLMENT_FREQUENCY', 'WRITE_OFF_DATE', '_OVERDUE_AMT',\n",
       "       '_WRITE_OFF_AMT', 'ASSET_CLASS', '_ACCOUNT_REMARKS', 'LINKED_ACCOUNTS',\n",
       "       'REPORTED_DATE__HIST_', 'DPD__HIST', 'ASSET_CLASS__HIST_',\n",
       "       'HIGH_CRD__HIST_', 'CUR_BAL__HIST_', 'DAS__HIST_', 'AMT_OVERDUE__HIST_',\n",
       "       'AMT_PAID__HIST_', 'INCOME_', '_INCOME_INDICATOR_', 'TENURE_',\n",
       "       '_OCCUPATION', 'Unnamed_41', 'DISBURSED_DT_goodbad'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv_retro_map.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-75-fb981f55ecd4>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['DISBURSED_DT_YRMTH']=df1['DISBURSED_DT'].dt.strftime('%Y-%m')\n",
      "<ipython-input-75-fb981f55ecd4>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['DATE_REPORTED_YRMTH']=df1['DATE_REPORTED'].dt.strftime('%Y-%m')\n",
      "<ipython-input-75-fb981f55ecd4>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['DISBURSED_DT_YR']=df1['DISBURSED_DT'].dt.strftime('%Y')\n",
      "<ipython-input-75-fb981f55ecd4>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['DATE_REPORTED_YR']=df1['DATE_REPORTED'].dt.strftime('%Y')\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "df1['DISBURSED_DT_YRMTH']=df1['DISBURSED_DT'].dt.strftime('%Y-%m')\n",
    "df1['DATE_REPORTED_YRMTH']=df1['DATE_REPORTED'].dt.strftime('%Y-%m')\n",
    "\n",
    "df1['DISBURSED_DT_YR']=df1['DISBURSED_DT'].dt.strftime('%Y')\n",
    "df1['DATE_REPORTED_YR']=df1['DATE_REPORTED'].dt.strftime('%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1634489, 48) (780113, 48)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-79-d8d13042102a>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['Monthdiff_less_than36_atleast18m'] = np.where((df1['Month_diff_betweenDisb_reported'] <=36) & (df1['Month_diff_betweenDisb_reported'] >=18), 1 , 0 )\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DISBURSED_DT_YR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>0</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>0</td>\n",
       "      <td>921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>0</td>\n",
       "      <td>5387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>0</td>\n",
       "      <td>16947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>0</td>\n",
       "      <td>21468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>20</td>\n",
       "      <td>25468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>1956</td>\n",
       "      <td>47334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>10932</td>\n",
       "      <td>73533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>28824</td>\n",
       "      <td>92818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>37235</td>\n",
       "      <td>94024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>45833</td>\n",
       "      <td>123234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>76046</td>\n",
       "      <td>205753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>81081</td>\n",
       "      <td>205958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>70088</td>\n",
       "      <td>208731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>49911</td>\n",
       "      <td>191125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>52672</td>\n",
       "      <td>124824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>50384</td>\n",
       "      <td>60294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>20151</td>\n",
       "      <td>75742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>0</td>\n",
       "      <td>59851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   sum   count\n",
       "DISBURSED_DT_YR               \n",
       "1992                 0       8\n",
       "1994                 0       3\n",
       "1995                 0       3\n",
       "1996                 0       6\n",
       "1997                 0       6\n",
       "1998                 0       5\n",
       "1999                 0      21\n",
       "2000                 0      38\n",
       "2001                 0      83\n",
       "2002                 0      61\n",
       "2003                 0     240\n",
       "2004                 0     603\n",
       "2005                 0     921\n",
       "2006                 0    5387\n",
       "2007                 0   16947\n",
       "2008                 0   21468\n",
       "2009                20   25468\n",
       "2010              1956   47334\n",
       "2011             10932   73533\n",
       "2012             28824   92818\n",
       "2013             37235   94024\n",
       "2014             45833  123234\n",
       "2015             76046  205753\n",
       "2016             81081  205958\n",
       "2017             70088  208731\n",
       "2018             49911  191125\n",
       "2019             52672  124824\n",
       "2020             50384   60294\n",
       "2021             20151   75742\n",
       "2022                 0   59851"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df1.shape, df1[df1['Month_diff_betweenDisb_reported'] <= 36 ].shape)\n",
    "df1['Monthdiff_less_than36_atleast18m'] = np.where((df1['Month_diff_betweenDisb_reported'] <=36) & (df1['Month_diff_betweenDisb_reported'] >=18), 1 , 0 )\n",
    "df1.groupby(['DISBURSED_DT_YR'])['Monthdiff_less_than36_atleast18m'].agg(['sum', 'count'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((525133, 48), (1634489, 48))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv= df1[df1['Monthdiff_less_than36_atleast18m']==1]\n",
    "df_cv.shape, df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df,df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CREDT_RPT_ID</th>\n",
       "      <th>LOS_APP_ID</th>\n",
       "      <th>CANDIDATE__ID</th>\n",
       "      <th>CUSTOMER_ID_MBR_ID</th>\n",
       "      <th>BRANCH</th>\n",
       "      <th>KENDRA</th>\n",
       "      <th>SELF_INDICATOR</th>\n",
       "      <th>MATCH_TYPE</th>\n",
       "      <th>ACC_NUM</th>\n",
       "      <th>CREDIT_GRANTOR</th>\n",
       "      <th>...</th>\n",
       "      <th>_INCOME_INDICATOR_</th>\n",
       "      <th>TENURE_</th>\n",
       "      <th>_OCCUPATION</th>\n",
       "      <th>Unnamed_41</th>\n",
       "      <th>Month_diff_betweenDisb_reported</th>\n",
       "      <th>DISBURSED_DT_YRMTH</th>\n",
       "      <th>DATE_REPORTED_YRMTH</th>\n",
       "      <th>DISBURSED_DT_YR</th>\n",
       "      <th>DATE_REPORTED_YR</th>\n",
       "      <th>Monthdiff_less_than36_atleast18m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VAST221114CR257974523894971</td>\n",
       "      <td>L022500180</td>\n",
       "      <td>253452087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.133986</td>\n",
       "      <td>2016-07</td>\n",
       "      <td>2018-08</td>\n",
       "      <td>2016</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VAST221114CR85724523894971</td>\n",
       "      <td>401300310033285</td>\n",
       "      <td>802673876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELF EMPLOYED</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.220436</td>\n",
       "      <td>2015-11</td>\n",
       "      <td>2018-10</td>\n",
       "      <td>2015</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>VAST221114CR886434523894971</td>\n",
       "      <td>3389357</td>\n",
       "      <td>4159712081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>OTHERS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.023306</td>\n",
       "      <td>2017-11</td>\n",
       "      <td>2020-10</td>\n",
       "      <td>2017</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>VAST221114CR456354523894971</td>\n",
       "      <td>137100310054159</td>\n",
       "      <td>270519689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.688371</td>\n",
       "      <td>2017-02</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>2017</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>VAST221114CR456354523894971</td>\n",
       "      <td>137100310054159</td>\n",
       "      <td>4969194642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.043718</td>\n",
       "      <td>2019-11</td>\n",
       "      <td>2022-04</td>\n",
       "      <td>2019</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   CREDT_RPT_ID       LOS_APP_ID  CANDIDATE__ID  \\\n",
       "2   VAST221114CR257974523894971       L022500180      253452087   \n",
       "7    VAST221114CR85724523894971  401300310033285      802673876   \n",
       "17  VAST221114CR886434523894971          3389357     4159712081   \n",
       "22  VAST221114CR456354523894971  137100310054159      270519689   \n",
       "26  VAST221114CR456354523894971  137100310054159     4969194642   \n",
       "\n",
       "    CUSTOMER_ID_MBR_ID BRANCH KENDRA  SELF_INDICATOR MATCH_TYPE ACC_NUM  \\\n",
       "2                  NaN    NaN    NaN           False    PRIMARY    XXXX   \n",
       "7                  NaN    NaN    NaN           False    PRIMARY    XXXX   \n",
       "17                 NaN    NaN    NaN           False    PRIMARY    XXXX   \n",
       "22                 NaN    NaN    NaN           False    PRIMARY    XXXX   \n",
       "26                 NaN    NaN    NaN           False    PRIMARY    XXXX   \n",
       "\n",
       "   CREDIT_GRANTOR  ... _INCOME_INDICATOR_ TENURE_    _OCCUPATION Unnamed_41  \\\n",
       "2            XXXX  ...                NaN    23.0            NaN        NaN   \n",
       "7            XXXX  ...                  M     NaN  SELF EMPLOYED        NaN   \n",
       "17           XXXX  ...                NaN    30.0         OTHERS        NaN   \n",
       "22           XXXX  ...                NaN    24.0            NaN        NaN   \n",
       "26           XXXX  ...                  M     NaN            NaN        NaN   \n",
       "\n",
       "   Month_diff_betweenDisb_reported DISBURSED_DT_YRMTH DATE_REPORTED_YRMTH  \\\n",
       "2                        25.133986            2016-07             2018-08   \n",
       "7                        35.220436            2015-11             2018-10   \n",
       "17                       35.023306            2017-11             2020-10   \n",
       "22                       23.688371            2017-02             2019-01   \n",
       "26                       29.043718            2019-11             2022-04   \n",
       "\n",
       "   DISBURSED_DT_YR DATE_REPORTED_YR Monthdiff_less_than36_atleast18m  \n",
       "2             2016             2018                                1  \n",
       "7             2015             2018                                1  \n",
       "17            2017             2020                                1  \n",
       "22            2017             2019                                1  \n",
       "26            2019             2022                                1  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv.to_pickle(\"df_cv_filtered.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv= pd.read_pickle(\"df_cv_filtered.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CREDT_RPT_ID</th>\n",
       "      <th>LOS_APP_ID</th>\n",
       "      <th>CANDIDATE__ID</th>\n",
       "      <th>CUSTOMER_ID_MBR_ID</th>\n",
       "      <th>BRANCH</th>\n",
       "      <th>KENDRA</th>\n",
       "      <th>SELF_INDICATOR</th>\n",
       "      <th>MATCH_TYPE</th>\n",
       "      <th>ACC_NUM</th>\n",
       "      <th>CREDIT_GRANTOR</th>\n",
       "      <th>...</th>\n",
       "      <th>_INCOME_INDICATOR_</th>\n",
       "      <th>TENURE_</th>\n",
       "      <th>_OCCUPATION</th>\n",
       "      <th>Unnamed_41</th>\n",
       "      <th>Month_diff_betweenDisb_reported</th>\n",
       "      <th>DISBURSED_DT_YRMTH</th>\n",
       "      <th>DATE_REPORTED_YRMTH</th>\n",
       "      <th>DISBURSED_DT_YR</th>\n",
       "      <th>DATE_REPORTED_YR</th>\n",
       "      <th>Monthdiff_less_than36_atleast18m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VAST221114CR257974523894971</td>\n",
       "      <td>L022500180</td>\n",
       "      <td>253452087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.133986</td>\n",
       "      <td>2016-07</td>\n",
       "      <td>2018-08</td>\n",
       "      <td>2016</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VAST221114CR85724523894971</td>\n",
       "      <td>401300310033285</td>\n",
       "      <td>802673876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELF EMPLOYED</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.220436</td>\n",
       "      <td>2015-11</td>\n",
       "      <td>2018-10</td>\n",
       "      <td>2015</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>VAST221114CR886434523894971</td>\n",
       "      <td>3389357</td>\n",
       "      <td>4159712081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>OTHERS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.023306</td>\n",
       "      <td>2017-11</td>\n",
       "      <td>2020-10</td>\n",
       "      <td>2017</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>VAST221114CR456354523894971</td>\n",
       "      <td>137100310054159</td>\n",
       "      <td>270519689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.688371</td>\n",
       "      <td>2017-02</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>2017</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>VAST221114CR456354523894971</td>\n",
       "      <td>137100310054159</td>\n",
       "      <td>4969194642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.043718</td>\n",
       "      <td>2019-11</td>\n",
       "      <td>2022-04</td>\n",
       "      <td>2019</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   CREDT_RPT_ID       LOS_APP_ID  CANDIDATE__ID  \\\n",
       "2   VAST221114CR257974523894971       L022500180      253452087   \n",
       "7    VAST221114CR85724523894971  401300310033285      802673876   \n",
       "17  VAST221114CR886434523894971          3389357     4159712081   \n",
       "22  VAST221114CR456354523894971  137100310054159      270519689   \n",
       "26  VAST221114CR456354523894971  137100310054159     4969194642   \n",
       "\n",
       "    CUSTOMER_ID_MBR_ID BRANCH KENDRA  SELF_INDICATOR MATCH_TYPE ACC_NUM  \\\n",
       "2                  NaN    NaN    NaN           False    PRIMARY    XXXX   \n",
       "7                  NaN    NaN    NaN           False    PRIMARY    XXXX   \n",
       "17                 NaN    NaN    NaN           False    PRIMARY    XXXX   \n",
       "22                 NaN    NaN    NaN           False    PRIMARY    XXXX   \n",
       "26                 NaN    NaN    NaN           False    PRIMARY    XXXX   \n",
       "\n",
       "   CREDIT_GRANTOR  ... _INCOME_INDICATOR_ TENURE_    _OCCUPATION Unnamed_41  \\\n",
       "2            XXXX  ...                NaN    23.0            NaN        NaN   \n",
       "7            XXXX  ...                  M     NaN  SELF EMPLOYED        NaN   \n",
       "17           XXXX  ...                NaN    30.0         OTHERS        NaN   \n",
       "22           XXXX  ...                NaN    24.0            NaN        NaN   \n",
       "26           XXXX  ...                  M     NaN            NaN        NaN   \n",
       "\n",
       "   Month_diff_betweenDisb_reported DISBURSED_DT_YRMTH DATE_REPORTED_YRMTH  \\\n",
       "2                        25.133986            2016-07             2018-08   \n",
       "7                        35.220436            2015-11             2018-10   \n",
       "17                       35.023306            2017-11             2020-10   \n",
       "22                       23.688371            2017-02             2019-01   \n",
       "26                       29.043718            2019-11             2022-04   \n",
       "\n",
       "   DISBURSED_DT_YR DATE_REPORTED_YR Monthdiff_less_than36_atleast18m  \n",
       "2             2016             2018                                1  \n",
       "7             2015             2018                                1  \n",
       "17            2017             2020                                1  \n",
       "22            2017             2019                                1  \n",
       "26            2019             2022                                1  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas-profiling\n",
      "  Using cached pandas_profiling-3.5.0-py2.py3-none-any.whl (325 kB)\n",
      "Requirement already satisfied: seaborn<0.13,>=0.10.1 in c:\\users\\romil\\anaconda\\lib\\site-packages (from pandas-profiling) (0.11.2)\n",
      "Collecting phik<0.13,>=0.11.1\n",
      "  Downloading phik-0.12.2-cp39-cp39-win_amd64.whl (685 kB)\n",
      "     -------------------------------------- 685.8/685.8 kB 8.7 MB/s eta 0:00:00\n",
      "Collecting pydantic<1.11,>=1.8.1\n",
      "  Downloading pydantic-1.10.2-cp39-cp39-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 5.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2<3.2,>=2.11.1 in c:\\users\\romil\\anaconda\\lib\\site-packages (from pandas-profiling) (2.11.3)\n",
      "Requirement already satisfied: tqdm<4.65,>=4.48.2 in c:\\users\\romil\\anaconda\\lib\\site-packages (from pandas-profiling) (4.64.1)\n",
      "Requirement already satisfied: pandas!=1.4.0,<1.6,>1.1 in c:\\users\\romil\\anaconda\\lib\\site-packages (from pandas-profiling) (1.4.4)\n",
      "Requirement already satisfied: statsmodels<0.14,>=0.13.2 in c:\\users\\romil\\anaconda\\lib\\site-packages (from pandas-profiling) (0.13.2)\n",
      "Requirement already satisfied: requests<2.29,>=2.24.0 in c:\\users\\romil\\anaconda\\lib\\site-packages (from pandas-profiling) (2.28.1)\n",
      "Collecting typeguard<2.14,>=2.13.2\n",
      "  Using cached typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Collecting htmlmin==0.1.12\n",
      "  Using cached htmlmin-0.1.12.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: scipy<1.10,>=1.4.1 in c:\\users\\romil\\anaconda\\lib\\site-packages (from pandas-profiling) (1.9.1)\n",
      "Collecting multimethod<1.10,>=1.4\n",
      "  Using cached multimethod-1.9-py3-none-any.whl (10 kB)\n",
      "Collecting visions[type_image_path]==0.7.5\n",
      "  Using cached visions-0.7.5-py3-none-any.whl (102 kB)\n",
      "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in c:\\users\\romil\\anaconda\\lib\\site-packages (from pandas-profiling) (6.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.16.0 in c:\\users\\romil\\anaconda\\lib\\site-packages (from pandas-profiling) (1.21.5)\n",
      "Requirement already satisfied: matplotlib<3.7,>=3.2 in c:\\users\\romil\\anaconda\\lib\\site-packages (from pandas-profiling) (3.5.2)\n",
      "Collecting tangled-up-in-unicode>=0.0.4\n",
      "  Using cached tangled_up_in_unicode-0.2.0-py3-none-any.whl (4.7 MB)\n",
      "Requirement already satisfied: attrs>=19.3.0 in c:\\users\\romil\\anaconda\\lib\\site-packages (from visions[type_image_path]==0.7.5->pandas-profiling) (21.4.0)\n",
      "Requirement already satisfied: networkx>=2.4 in c:\\users\\romil\\anaconda\\lib\\site-packages (from visions[type_image_path]==0.7.5->pandas-profiling) (2.8.4)\n",
      "Collecting imagehash\n",
      "  Using cached ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
      "Requirement already satisfied: Pillow in c:\\users\\romil\\anaconda\\lib\\site-packages (from visions[type_image_path]==0.7.5->pandas-profiling) (9.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\romil\\anaconda\\lib\\site-packages (from jinja2<3.2,>=2.11.1->pandas-profiling) (2.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\romil\\anaconda\\lib\\site-packages (from matplotlib<3.7,>=3.2->pandas-profiling) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\romil\\anaconda\\lib\\site-packages (from matplotlib<3.7,>=3.2->pandas-profiling) (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\romil\\anaconda\\lib\\site-packages (from matplotlib<3.7,>=3.2->pandas-profiling) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\romil\\anaconda\\lib\\site-packages (from matplotlib<3.7,>=3.2->pandas-profiling) (4.25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\romil\\anaconda\\lib\\site-packages (from matplotlib<3.7,>=3.2->pandas-profiling) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\romil\\anaconda\\lib\\site-packages (from matplotlib<3.7,>=3.2->pandas-profiling) (0.11.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\romil\\anaconda\\lib\\site-packages (from pandas!=1.4.0,<1.6,>1.1->pandas-profiling) (2022.1)\n",
      "Requirement already satisfied: joblib>=0.14.1 in c:\\users\\romil\\anaconda\\lib\\site-packages (from phik<0.13,>=0.11.1->pandas-profiling) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\romil\\anaconda\\lib\\site-packages (from pydantic<1.11,>=1.8.1->pandas-profiling) (4.3.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\romil\\anaconda\\lib\\site-packages (from requests<2.29,>=2.24.0->pandas-profiling) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\romil\\anaconda\\lib\\site-packages (from requests<2.29,>=2.24.0->pandas-profiling) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\romil\\anaconda\\lib\\site-packages (from requests<2.29,>=2.24.0->pandas-profiling) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\romil\\anaconda\\lib\\site-packages (from requests<2.29,>=2.24.0->pandas-profiling) (3.3)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\romil\\anaconda\\lib\\site-packages (from statsmodels<0.14,>=0.13.2->pandas-profiling) (0.5.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\romil\\anaconda\\lib\\site-packages (from tqdm<4.65,>=4.48.2->pandas-profiling) (0.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\romil\\anaconda\\lib\\site-packages (from patsy>=0.5.2->statsmodels<0.14,>=0.13.2->pandas-profiling) (1.16.0)\n",
      "Requirement already satisfied: PyWavelets in c:\\users\\romil\\anaconda\\lib\\site-packages (from imagehash->visions[type_image_path]==0.7.5->pandas-profiling) (1.3.0)\n",
      "Building wheels for collected packages: htmlmin\n",
      "  Building wheel for htmlmin (setup.py): started\n",
      "  Building wheel for htmlmin (setup.py): finished with status 'done'\n",
      "  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27082 sha256=52132bde09bed01d5491588bd37aa37ad95519d44c13956b72df86e426917029\n",
      "  Stored in directory: c:\\users\\romil\\appdata\\local\\pip\\cache\\wheels\\1d\\05\\04\\c6d7d3b66539d9e659ac6dfe81e2d0fd4c1a8316cc5a403300\n",
      "Successfully built htmlmin\n",
      "Installing collected packages: htmlmin, typeguard, tangled-up-in-unicode, pydantic, multimethod, imagehash, visions, phik, pandas-profiling\n",
      "Successfully installed htmlmin-0.1.12 imagehash-4.3.1 multimethod-1.9 pandas-profiling-3.5.0 phik-0.12.2 pydantic-1.10.2 tangled-up-in-unicode-0.2.0 typeguard-2.13.3 visions-0.7.5\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d0cb964efc4870952cd5976df5ede3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romil\\Anaconda\\lib\\site-packages\\scipy\\stats\\_stats_py.py:110: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  warnings.warn(\"The input array could not be properly \"\n",
      "C:\\Users\\romil\\Anaconda\\lib\\site-packages\\scipy\\stats\\_stats_py.py:110: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  warnings.warn(\"The input array could not be properly \"\n",
      "C:\\Users\\romil\\Anaconda\\lib\\site-packages\\scipy\\stats\\_stats_py.py:110: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  warnings.warn(\"The input array could not be properly \"\n",
      "C:\\Users\\romil\\Anaconda\\lib\\site-packages\\scipy\\stats\\_stats_py.py:110: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  warnings.warn(\"The input array could not be properly \"\n",
      "C:\\Users\\romil\\Anaconda\\lib\\site-packages\\scipy\\stats\\_stats_py.py:110: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  warnings.warn(\"The input array could not be properly \"\n",
      "C:\\Users\\romil\\Anaconda\\lib\\site-packages\\scipy\\stats\\_stats_py.py:110: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  warnings.warn(\"The input array could not be properly \"\n",
      "C:\\Users\\romil\\Anaconda\\lib\\site-packages\\pandas_profiling\\model\\correlations.py:67: UserWarning: There was an attempt to calculate the auto correlation, but this failed.\n",
      "To hide this warning, disable the calculation\n",
      "(using `df.profile_report(correlations={\"auto\": {\"calculate\": False}})`\n",
      "If this is problematic for your use case, please report this as an issue:\n",
      "https://github.com/ydataai/pandas-profiling/issues\n",
      "(include the error message: 'No data; `observed` has size 0.')\n",
      "  warnings.warn(\n",
      "C:\\Users\\romil\\Anaconda\\lib\\site-packages\\scipy\\stats\\_stats_py.py:5215: RuntimeWarning: overflow encountered in longlong_scalars\n",
      "  (2 * xtie * ytie) / m + x0 * y0 / (9 * m * (size - 2)))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a0b7a24e1674df6bd9a91735272366b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5378b3172a2d48caa01cc377cee6fc52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46adfe9dd87145b48faffa74cd63d9bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas_profiling as pp\n",
    "  \n",
    "# forming ProfileReport and save\n",
    "# as output.html file\n",
    "profile = pp.ProfileReport(df_cv)\n",
    "profile.to_file(\"EDA_pp.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['AMT_OVERDUE__HIST_','AMT_PAID__HIST_','CUR_BAL__HIST_']\n",
    "\n",
    "df_cv['DISBURSED_DT'] = pd.to_datetime(df_cv['DISBURSED_DT'],format=\"%d-%m-%Y\",errors='coerce')\n",
    "df_cv['DATE_REPORTED'] = pd.to_datetime(df_cv['DATE_REPORTED'],format=\"%d-%m-%Y\",errors='coerce')\n",
    "\n",
    "\n",
    "temp = pd.concat([df_cv[['LOS_APP_ID','CANDIDATE__ID' , 'DISBURSED_DT', 'DATE_REPORTED',\"AMT_OVERDUE__HIST_\"]], df_cv[\"AMT_OVERDUE__HIST_\"].str.split(',', expand=True)], axis=1)\n",
    "\n",
    "translist = list(set(temp.columns) - set(['LOS_APP_ID','CANDIDATE__ID' , 'DISBURSED_DT', 'DATE_REPORTED',\"AMT_OVERDUE__HIST_\"]))\n",
    "\n",
    "temp_l = pd.melt(temp, id_vars=['LOS_APP_ID','CANDIDATE__ID' , 'DISBURSED_DT', 'DATE_REPORTED'], value_vars=translist )\n",
    "temp_l.rename(columns={'value': 'AMT_OVERDUE__HIST_'}, inplace=True)\n",
    "\n",
    "temp_l['variable'] = temp_l['variable'].astype('int')\n",
    "temp_l['variable'] = temp_l['variable'].fillna(36)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOS_APP_ID</th>\n",
       "      <th>CANDIDATE__ID</th>\n",
       "      <th>DISBURSED_DT</th>\n",
       "      <th>DATE_REPORTED</th>\n",
       "      <th>variable</th>\n",
       "      <th>AMT_OVERDUE__HIST_</th>\n",
       "      <th>Mont_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L022500180</td>\n",
       "      <td>253452087</td>\n",
       "      <td>2016-07-27</td>\n",
       "      <td>2018-08-31</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>25.133986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>401300310033285</td>\n",
       "      <td>802673876</td>\n",
       "      <td>2015-11-24</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.220436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3389357</td>\n",
       "      <td>4159712081</td>\n",
       "      <td>2017-11-30</td>\n",
       "      <td>2020-10-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.023306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>137100310054159</td>\n",
       "      <td>270519689</td>\n",
       "      <td>2017-02-09</td>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.688371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137100310054159</td>\n",
       "      <td>4969194642</td>\n",
       "      <td>2019-11-28</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.043718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        LOS_APP_ID  CANDIDATE__ID DISBURSED_DT DATE_REPORTED  variable  \\\n",
       "0       L022500180      253452087   2016-07-27    2018-08-31         0   \n",
       "1  401300310033285      802673876   2015-11-24    2018-10-31         0   \n",
       "2          3389357     4159712081   2017-11-30    2020-10-31         0   \n",
       "3  137100310054159      270519689   2017-02-09    2019-01-31         0   \n",
       "4  137100310054159     4969194642   2019-11-28    2022-04-30         0   \n",
       "\n",
       "  AMT_OVERDUE__HIST_  Mont_diff  \n",
       "0                     25.133986  \n",
       "1                  0  35.220436  \n",
       "2                  0  35.023306  \n",
       "3                  0  23.688371  \n",
       "4                  0  29.043718  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_l['Mont_diff'] = ((temp_l.DATE_REPORTED - pd.to_datetime(temp_l.DISBURSED_DT) )/np.timedelta64(1, 'M')) + temp_l['variable']\n",
    "temp_l.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
